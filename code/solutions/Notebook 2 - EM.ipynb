{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cd1b47",
   "metadata": {},
   "source": [
    "<img src=\"resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Workshop SWDB 2024 </h1> \n",
    "<h3 align=\"center\">Day 3 2024 - Neuron Morphology</h3> \n",
    "<h3 align=\"center\">Notebook 3: EM Connectomics</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b52f10-7320-4b18-9b78-44cbcd5a7a32",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "<b> Electron Microscopy (EM) data enables morphological reconstruction of neurons and detection of their synaptic connectivity </b>. The <a href=https://www.microns-explorer.org/cortical-mm3>MICrONS dataset </a> is one of the largest datasets currently available spanning all layers of visual cortex. We will be using this dataset to query the connectivity between the excitatory neurons in the visual cortex. The exercises will cover the connectivity with inhibitory neurons. \n",
    "\n",
    "    \n",
    "<em> Note on the data: </em> To make our lifes easier, we already queried the necessary data from the database and made it available as files that can be readily read with pandas. The entire dataset is hosted using the <a href=https://caveconnectome.github.io/sections/cave_overview.html> Connectome Annotation Versioning Engine (CAVE) </a>. A separate notebook shows how to use CAVE and how the files used in this notebook were created. \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855f4721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join \u001b[38;5;28;01mas\u001b[39;00m pjoin\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskeleton_plot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mskelplot\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmeshparty\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudvolume\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skeleton_plot/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0.8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_tools\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skeleton_plot/plot_tools.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LineCollection\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeshparty\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m meshwork, skeleton\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      9\u001b[0m axis_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/meshparty/meshwork/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeshwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Meshwork, load_meshwork\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m algorithms\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/meshparty/meshwork/meshwork.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m     _vtk_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskeleton_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m swc_node_labels\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrimesh_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mesh\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskeleton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Skeleton, resample\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/meshparty/trimesh_io.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wraps\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudvolume\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcloudvolume\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprecomputed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmesh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultilod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedMultiLevelPrecomputedMeshSource\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiwrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiprocessing_utils \u001b[38;5;28;01mas\u001b[39;00m mu\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudvolume/__init__.py:49\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mA \"serverless\" Python client for reading and writing arbitrarily large \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mNeuroglancer Precomputed volumes both locally and on cloud services. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m  skel = vol.skeletons.get(label)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloudvolume\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CloudVolume, register_plugin\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConnectionPool\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bbox, Vec\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudvolume/cloudvolume.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnsupportedFormatError, DimensionError, InfoUnavailableError\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_random_string\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strict_extract, to_https_protocol\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudvolume/exceptions.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcloudfiles\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompressionError, DecompressionError\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAuthenticationError\u001b[39;00m(\u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Incorrect credentials.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudfiles/__init__.py:12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mCloudFiles is a multithreaded key-value object\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mmanagement client that supports GET, PUT, DELETE,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mservers.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloudfiles\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CloudFile, CloudFiles, dl\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reset_connection_pools\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_memory\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudfiles/cloudfiles.py:44\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m   CompressType, GetPathType, PutScalarType,\n\u001b[1;32m     40\u001b[0m   PutType, ParallelType, SecretsType\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schedule_jobs\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m   FileInterface, HttpInterface, \n\u001b[1;32m     46\u001b[0m   S3Interface, GoogleCloudStorageInterface,\n\u001b[1;32m     47\u001b[0m   MemoryInterface, CaveInterface,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m INTERFACES \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m: FileInterface,\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs\u001b[39m\u001b[38;5;124m'\u001b[39m: GoogleCloudStorageInterface,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiddleauth+https\u001b[39m\u001b[38;5;124m'\u001b[39m: CaveInterface,\n\u001b[1;32m     58\u001b[0m }\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alias \u001b[38;5;129;01min\u001b[39;00m ALIASES:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloudfiles/interfaces.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mposixpath\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgevent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonkey\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/boto3/__init__.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _warn_deprecated_python\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Session\n\u001b[1;32m     19\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmazon Web Services\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.34.162\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/boto3/session.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataNotFoundError, UnknownServiceError\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/session.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msocket\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigloader\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ANY KIND, either express or implied. See the License for the specific\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# language governing permissions and limitations under the License.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m waiter, xform_name\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientArgsCreator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTH_TYPE_MAPS\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjmespath\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WaiterDocstring\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_service_module_name\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xform_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/docs/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ANY KIND, either express or implied. See the License for the specific\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# language governing permissions and limitations under the License.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServiceDocumenter\n\u001b[1;32m     17\u001b[0m DEPRECATED_SERVICE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msms-voice\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_docs\u001b[39m(root_dir, session):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/docs/service.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ANY KIND, either express or implied. See the License for the specific\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# language governing permissions and limitations under the License.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbcdoc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrestdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentStructure\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     ClientContextParamsDocumenter,\n\u001b[1;32m     16\u001b[0m     ClientDocumenter,\n\u001b[1;32m     17\u001b[0m     ClientExceptionsDocumenter,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaginator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaginatorDocumenter\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwaiter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WaiterDocumenter\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/docs/client.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbcdoc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrestdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentStructure\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResponseExampleDocumenter\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     document_custom_method,\n\u001b[1;32m     21\u001b[0m     document_model_driven_method,\n\u001b[1;32m     22\u001b[0m     get_instance_public_methods,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResponseParamsDocumenter\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:674\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:577\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:558\u001b[0m, in \u001b[0;36m_init_module_attrs\u001b[0;34m(spec, module, override)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:391\u001b[0m, in \u001b[0;36mcached\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import skeleton_plot as skelplot\n",
    "import meshparty\n",
    "import cloudvolume\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # to access utils folder\n",
    "from utils.skeleton_loading_utils import load_cv_skeleton\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862c9b9-4ba4-4ad6-9193-71fcc7003dc2",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "This cell sets up a variable called `data_root` that you should use in any code below to access the dataset in question (e.g. paths to manifest files for the SDK should be made relative to this variable).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bf502-9fa9-4f54-b3f4-472cc470e1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/anatomy/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/anatomy/\"\n",
    "elif ('amzn2' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/anatomy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaa4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize cloud volume to access the EM skeletons\n",
    "cv_obj = cloudvolume.CloudVolume(f\"file://{data_root}/em_minnie65_v1078\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79818cf3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "## Proofreading information\n",
    "\n",
    "\n",
    "Proofreading is necessary to obtain accurate reconstructions of a cell. In the MICrONS dataset, the general rule is that dendrites onto cells with a cell body are sufficiently proofread to trust synaptic connections onto a cell. Axons on the other hand require so much proofreading that only ~1,200 cells have proofread axons, 600 of which used a strategy that did not fully extend the axon (`axon_column_truncated`).\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7938b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_df = pd.read_feather(pjoin(data_root,\"microns1078\",\"proofread_axons_microns_1078.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9105ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_columns = ['id',\n",
    " 'pt_root_id',\n",
    " 'status_dendrite',\n",
    " 'status_axon', \n",
    " 'strategy_dendrite',\n",
    " 'strategy_axon',\n",
    " 'pt_position_x',\n",
    " 'pt_position_y',\n",
    " 'pt_position_z']\n",
    "proof_df[proof_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5ddd6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Every annotation table has at least one set of position columns (here: `pt_position_{x,y,z}`) which serves as anchor to the segmentation. These positions are automatically associated to the segmentation using `pt_root_id`s which can be thought of segment or cell IDs.\n",
    "\n",
    "This contains proofreading information for all neurons with proofread axons. We distinguish with what goal a proofreader proofread an axon; see <a href=https://www.microns-explorer.org/manifests/mm3-proofreading> this website </a>for a detailed overview.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a2620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_df[\"strategy_axon\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2a7cc",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Using the plotting logic introduced in the first notebook, we will start by visualizing an individual neuron. Over the course of this notebook we will annotate this neuron with increasingly more detailed synaptic connectivity.\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406467e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_skeleton(sk: meshparty.skeleton.Skeleton):\n",
    "    \"\"\"Plots a skeleton.\n",
    "    \n",
    "    Args:\n",
    "        sk: meshparty skeleton\n",
    "        \n",
    "    Returns: \n",
    "        ax: plot axes\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 10))\n",
    "    skelplot.plot_tools.plot_skel(\n",
    "        sk,\n",
    "        ax=ax,\n",
    "        line_width = 1,\n",
    "        plot_soma = True,\n",
    "        invert_y = True,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "    )\n",
    "\n",
    "    ax.spines['right'].set_visible(False) \n",
    "    ax.spines['left'].set_visible(False) \n",
    "    ax.spines['top'].set_visible(False) \n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66d622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_id = proof_df.iloc[2][\"pt_root_id\"]\n",
    "sk = load_cv_skeleton(root_id, cv_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91155138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_skeleton(sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664503b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Synaptic connectivity\n",
    "\n",
    "Next, we will add synaptic connections to this neuron. We load the prepared table with the synaptic connectivity\n",
    "\n",
    "This table has a number of columns, we will highlight the most important\n",
    "\n",
    "<strong>id</strong>: a unique ID for each synapse\n",
    "\n",
    "<strong>pre_pt_root_id</strong>: the segmentation ID of the pre-synaptic compartment\n",
    "\n",
    "<strong>post_pt_root_id</strong>: the segmentation ID of the post-synaptic compartment\n",
    "\n",
    "<strong>size</strong>: a measure of the synapse size  (the number of 4,4,40 nm voxels in the synapse mask) best available metric of synaptic weight\n",
    "\n",
    "<strong>ctr_pt_position_{x,y,z}</strong>: the location of the synapse in the cleft, stored here in nanometers\n",
    "\n",
    "<strong>pre_pt_position_{x,y,z}</strong>: a point just in the presynaptic compartment of synapse (used to lookup pre_root_id), stored here in nanometers\n",
    "\n",
    "<strong>post_pt_position_{x,y,z}</strong>: a point just in the postsynaptic compartment of synapse (used to lookup post_pt_root_id), stored here in nanomaters\n",
    "\n",
    "Other columns that are not very relevant for you..\n",
    "\n",
    "<strong>created</strong>: when this synapse was uploaded\n",
    "    \n",
    "<strong>superceded_id</strong>: who this annotation was replaced by (no synapses have been)\n",
    "    \n",
    "<strong>valid</strong>: did annotation pass internal data QC check\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d797c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_syn_table = pd.read_feather(pjoin(data_root,\"microns1078\", \"syn_proofread_axons_all_microns_1078.feather\"))\n",
    "proof_syn_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040834b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_columns = ['id',\n",
    "'ctr_pt_position_x', \n",
    "'ctr_pt_position_y', \n",
    "'ctr_pt_position_y',\n",
    "'size',\n",
    "'pre_pt_root_id', \n",
    "'post_pt_root_id']\n",
    "proof_syn_table[proof_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717713a1",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "The synapse table contains snapses pre- and postsynaptic of all neurons in the proofreading table. This function provides filtering logic to extract synapses that belong to a specific set of neurons. \n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e26f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_synapse_table(synapse_table: pd.DataFrame, pre_root_ids=None, post_root_ids=None):   \n",
    "    \"\"\"Filter synapse table by pre and post root ids.\n",
    "\n",
    "    Args:\n",
    "        synapse_table: synapse table with pre_pt_root_ids and post_pt_root_ids as pd.DataFrame\n",
    "        pre_root_ids: np.ndarray, list or pd.Series if root_ids to filter on the presynaptic side\n",
    "        post_root_ids: np.ndarray, list or pd.Series if root_ids to filter on the postsynaptic side\n",
    "\n",
    "    Returns:\n",
    "        synapse_table: filtered synapse table\n",
    "    \"\"\"\n",
    "    \n",
    "    if pre_root_ids is not None:\n",
    "        assert isinstance(pre_root_ids, (np.ndarray, list, pd.core.series.Series)), f\"IDs have to be of type np.ndarray, list or pd.Series; got {type(pre_root_ids)}\"\n",
    "        pre_m = np.isin(synapse_table[\"pre_pt_root_id\"], pre_root_ids)\n",
    "    else:\n",
    "        pre_m = np.ones(len(synapse_table), dtype=bool)\n",
    "        \n",
    "    if post_root_ids is not None:\n",
    "        assert isinstance(post_root_ids, (np.ndarray, list, pd.core.series.Series)), f\"IDs have to be of type np.ndarray, list or pd.Series; got {type(pre_root_ids)}\"\n",
    "        post_m = np.isin(synapse_table[\"post_pt_root_id\"], post_root_ids)\n",
    "    else:\n",
    "        post_m = np.ones(len(synapse_table), dtype=bool)\n",
    "        \n",
    "    return synapse_table[pre_m & post_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7863e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "We extract all synapses that our neuron of interest makes onto other neurons in the dataset by filtering on the presynaptic side:\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74759966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_syns = filter_synapse_table(proof_syn_table, pre_root_ids=[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88a89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = plot_skeleton(sk)\n",
    "\n",
    "sns.scatterplot(data=pre_syns, x=\"pre_pt_position_x\", y=\"pre_pt_position_y\", \n",
    "                s=10, color=\"b\", ax=ax, edgecolor=None) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7dd91d",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1:</b> Use the filter function above to create a dataframe of all postsynaptic synapses and create a version of the plot above that includes these postsynaptic synapses. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a194161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_syns = filter_synapse_table(proof_syn_table, post_root_ids=[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3795123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = plot_skeleton(sk)\n",
    "\n",
    "sns.scatterplot(data=pre_syns, x=\"pre_pt_position_x\", y=\"pre_pt_position_y\", \n",
    "                s=10, color=\"b\", ax=ax, edgecolor=None) \n",
    "\n",
    "sns.scatterplot(data=post_syns, x=\"post_pt_position_x\", y=\"post_pt_position_y\", \n",
    "                s=10, color=\"g\", ax=ax, edgecolor=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166376a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Synapse matrix\n",
    "\n",
    "The synapses of neurons create a network of synaptic connections. One way of visualizing this connectivity is in a matrix form. Pandas provides the `pivot_table` function that we can use to make a matrix out of the tabular synapse data. For now, we will limit ourselves to the synapses between the proofread neurons.\n",
    "    \n",
    "Each synapses has a `size` value assigned to it. How to aggregate the sizes from multiple synapes between two neurons depends on the research question. Synapse sizes vary by a lot and are related to the physiological strength of a synapse. In this notebook, we ignore the synapse size and only look at binary (connected yes/no) connectivity.\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0217d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proof_proof_syn_table = filter_synapse_table(proof_syn_table, pre_root_ids=proof_df[\"pt_root_id\"], post_root_ids=proof_df[\"pt_root_id\"])\n",
    "\n",
    "syn_mat = proof_proof_syn_table.pivot_table(index=\"pre_pt_root_id\", columns=\"post_pt_root_id\", \n",
    "                                            values=\"size\", aggfunc=lambda x: float(np.sum(x) > 0)).fillna(0)\n",
    "\n",
    "# Make matrix is quadratic\n",
    "syn_mat = syn_mat.reindex(columns=np.array(syn_mat.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93162af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.heatmap(syn_mat, cmap=\"gray_r\", xticklabels=[], yticklabels=[], \n",
    "            ax=ax, square=True,\n",
    "            cbar_kws={\"label\": \"Connected - binary\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45534ba6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Adding cell type information\n",
    "    \n",
    "The synapse matrix above clearly contains a lot of information but no real structure is visible that we could interpret. Cell type information can help us to sort to this matrix and make connectivity patterns visible. \n",
    "    \n",
    "Cell types can be assigned based on different features of a cell and come with different levels of resolution. The cell types we will be using here at first were manually assigned by experts and represent an intermediate level of resolution in the cell type hierarchy.\n",
    "    \n",
    "In this notebook, we will focus on the excitatory neurons. The exercise notebook expands this to include inhibitory neurons.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea253c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type_df = pd.read_feather(pjoin(data_root,\"microns1078\", \"cell_types_microns_1078_manual.feather\"))\n",
    "cell_type_df = cell_type_df[cell_type_df[\"classification_system\"] == \"aibs_coarse_excitatory\"]\n",
    "cell_type_df = cell_type_df[cell_type_df[\"cell_type\"] != \"Unsure E\"]\n",
    "cell_type_df = cell_type_df[np.isin(cell_type_df[\"pt_root_id\"], proof_df[\"pt_root_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff0b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type_df[\"cell_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee210ad9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Sorting the synapse matrix with cell types\n",
    "    \n",
    "Let's combine the synaptic connecitivity with the cell type information. Below we provide logic for sorting a connectivity matrix using a list of labels.    \n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129df2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_matrix_by_types(mat: pd.DataFrame, \n",
    "                         labels: pd.DataFrame, \n",
    "                         label_type_col: str = \"cell_type\", \n",
    "                         label_id_col: str = \"pt_root_id\", \n",
    "                         post_labels: pd.DataFrame = None, \n",
    "                         post_label_type_col: str = None, \n",
    "                         post_label_id_col: str = None):\n",
    "    \"\"\"Sorts (synapse) matrix by labels.\n",
    "\n",
    "    This function assumes a square synapse matrix!\n",
    "\n",
    "    Args:\n",
    "        mat: synapse matrix as pandas DataFrame\n",
    "        labels: DataFrame with labels, e.g. the output of client.materialize.query_table('aibs_metamodel_celltypes_v661')\n",
    "        label_type_col: column name in labels for cell types\n",
    "        label_id_col: column name in labels for root ids\n",
    "        post_labels: DataFrame with labels, e.g. the output of client.materialize.query_table('aibs_metamodel_celltypes_v661')\n",
    "        post_label_type_col: column name in labels for cell types\n",
    "        post_label_id_col: column name in labels for root ids\n",
    "\n",
    "    Returns:\n",
    "        mat_sorted: sorted matrix\n",
    "        mat_labels: sorted labels; has the same length as matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    if post_labels is None:\n",
    "        post_labels = labels\n",
    "    if post_label_type_col is None:\n",
    "        post_label_type_col = label_type_col\n",
    "    if post_label_id_col is None:\n",
    "        post_label_id_col = label_id_col\n",
    "        \n",
    "    mat_sorted = mat.copy()\n",
    "    \n",
    "    pre_mat_labels = np.array(labels.set_index(label_id_col).loc[mat_sorted.index][label_type_col])\n",
    "    pre_sorting = np.argsort(pre_mat_labels)\n",
    "\n",
    "    post_mat_labels = np.array(post_labels.set_index(post_label_id_col).loc[mat_sorted.T.index][post_label_type_col])\n",
    "    post_sorting = np.argsort(post_mat_labels)\n",
    "\n",
    "    mat_sorted = mat_sorted.iloc[pre_sorting].T.iloc[post_sorting].T\n",
    "\n",
    "    return mat_sorted, pre_mat_labels[pre_sorting], post_mat_labels[post_sorting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc2db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct_ct_syn_table = filter_synapse_table(proof_syn_table, pre_root_ids=cell_type_df[\"pt_root_id\"], post_root_ids=cell_type_df[\"pt_root_id\"])\n",
    "\n",
    "\n",
    "syn_mat = ct_ct_syn_table.pivot_table(index=\"pre_pt_root_id\", columns=\"post_pt_root_id\", \n",
    "                                      values=\"size\", aggfunc=lambda x: float(np.sum(x) > 0)).fillna(0)\n",
    "\n",
    "syn_mat = syn_mat.reindex(columns=np.array(syn_mat.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6868fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "syn_mat_ct, syn_mat_cell_types, _ = sort_matrix_by_types(syn_mat, cell_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7ad41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cts, ct_idx = np.unique(syn_mat_cell_types, return_inverse=True)\n",
    "ct_colors = plt.get_cmap(\"tab10\")(ct_idx)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.heatmap(syn_mat_ct, cmap=\"gray_r\", xticklabels=[], yticklabels=[], \n",
    "            ax=ax, square=True,\n",
    "            cbar_kws={\"label\": \"Connected - binary\"})\n",
    "\n",
    "\n",
    "# Adding row and column colors for cell types\n",
    "for i, color in enumerate(ct_colors):\n",
    "    ax.add_patch(plt.Rectangle(xy=(-0.01, i), width=0.01, height=1, color=color, lw=0,\n",
    "                               transform=ax.get_yaxis_transform(), clip_on=False, label=color))\n",
    "\n",
    "for i, color in enumerate(ct_colors):\n",
    "    ax.add_patch(plt.Rectangle(xy=(i, 1), height=0.01, width=1, color=color, lw=0,\n",
    "                               transform=ax.get_xaxis_transform(), clip_on=False, label=color))    \n",
    "# fig.legend()\n",
    "from matplotlib.lines import Line2D\n",
    "# add a legend for the cell types\n",
    "legend_elements = [Line2D([0], [0], color=plt.get_cmap(\"tab10\")(i), label=ct) for i, ct in enumerate(cts)]\n",
    "plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.3, 1), title=\"cell types\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6b800",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Adding automatocally inferred cell type information\n",
    "    \n",
    "My limiting us to synapses between the proofread neurons, we ignore hundreds of outputs that we could analyze. However, annotating all cells in the dataset manually is a lot of work. To overcome this, we trained classifiers based on the manual features. The classification approach to predict the cell types used in this notebook is described <a href=https://www.biorxiv.org/content/10.1101/2022.07.20.499976v2.abstract>this paper </a>. This classifier predicts cell types based on the soma of a cell. This means that only cells with a soma in the dataset will have a cell type attached to it. Again, we will only focus on the excitatory neurons for now.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e62dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type_file_path = pjoin(data_root,\"microns1078\",\"cell_types_microns_1078_auto.feather\" )\n",
    "post_cell_type_df = pd.read_feather(cell_type_file_path)\n",
    "post_cell_type_df = post_cell_type_df[post_cell_type_df[\"classification_system\"] == \"excitatory_neuron\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaea89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_cell_type_df[\"cell_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8d7cb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Let's revisit our neuron from earlier for which we plotted the synapses along the axon. We will now add the cell type information to the synapses.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ab76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_id = proof_df.iloc[2][\"pt_root_id\"]\n",
    "\n",
    "sk = load_cv_skeleton(root_id, cv_obj)\n",
    "pre_syns = filter_synapse_table(proof_syn_table, pre_root_ids=[root_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c0fba",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "`merge` allows us to combine two tables based on columns that match between them. We use `merge` on the root ids to add cell type information to the synapses. Not all synapses are onto a segment that has a cell body in the dataset. Here, we are adding an `Unknown` label to these synapses.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0df6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_syns_annot = pd.merge(pre_syns, post_cell_type_df[[\"pt_root_id\", \"cell_type\"]], left_on=\"post_pt_root_id\", right_on=\"pt_root_id\", how=\"left\")\n",
    "pre_syns_annot[\"cell_type\"].fillna(\"Unknown\", inplace=True)\n",
    "pre_syns_annot[\"cell_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bb0a1",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2:</b> Use the `pre_syns_annot` table to plot the synapses along with the skeleton as we did before. Using the `hue` parameter of `sns.scatterplot`, color the synapses by cell type.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59c393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = plot_skeleton(sk)\n",
    "\n",
    "sns.scatterplot(data=pre_syns_annot, x=\"pre_pt_position_x\", y=\"pre_pt_position_y\", \n",
    "                s=20, hue=\"cell_type\", palette=\"tab10\", ax=ax, edgecolor=None) \n",
    "ax.legend(frameon=False, loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8992d43",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Extending the connectivity matrix\n",
    "    \n",
    "The automated cell type predictions allow us to extend the synapse matrix. This synapse matrix will now be rectangular because we have many more postsynaptic targets than presynaptic neurons.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74268e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct_ct_syn_table = filter_synapse_table(proof_syn_table, pre_root_ids=cell_type_df[\"pt_root_id\"], post_root_ids=post_cell_type_df[\"pt_root_id\"])\n",
    "\n",
    "\n",
    "syn_mat_rect = ct_ct_syn_table.pivot_table(index=\"pre_pt_root_id\", columns=\"post_pt_root_id\", \n",
    "                                      values=\"size\", aggfunc=lambda x: float(np.sum(x) > 0)).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c979a3",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3:</b> Use the plotting logic from above to plot the rectangular synaptic wiring diagram without cell type information.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870fc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.heatmap(syn_mat_rect, cmap=\"gray_r\", xticklabels=[], yticklabels=[], \n",
    "            ax=ax, square=False,\n",
    "            cbar_kws={\"label\": \"Connected - binary\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8ecfd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Finally, we can use the automated cell type information to sort this matrix and plot it.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee15369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "syn_mat_rect_ct, pre_syn_mat_cell_types, post_syn_mat_cell_types = sort_matrix_by_types(syn_mat_rect, cell_type_df, post_labels=post_cell_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cedc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_cts, pre_ct_idx = np.unique(pre_syn_mat_cell_types, return_inverse=True)\n",
    "row_ct_colors = plt.get_cmap(\"tab10\")(pre_ct_idx)\n",
    "\n",
    "post_cts, post_ct_idx = np.unique(post_syn_mat_cell_types, return_inverse=True)\n",
    "col_ct_colors = plt.get_cmap(\"tab10\")(post_ct_idx)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.heatmap(syn_mat_rect_ct, cmap=\"gray_r\", xticklabels=[], yticklabels=[], \n",
    "            ax=ax, square=False,\n",
    "            cbar_kws={\"label\": \"Connected - binary\"})\n",
    "\n",
    "# Adding row and column colors for cell types\n",
    "for i, color in enumerate(row_ct_colors):\n",
    "    ax.add_patch(plt.Rectangle(xy=(-0.01, i), width=0.005, height=1, color=color, lw=0,\n",
    "                               transform=ax.get_yaxis_transform(), clip_on=False))\n",
    "\n",
    "for i, color in enumerate(col_ct_colors):\n",
    "    ax.add_patch(plt.Rectangle(xy=(i, 1), height=0.01, width=1, color=color, lw=0,\n",
    "                               transform=ax.get_xaxis_transform(), clip_on=False))    \n",
    "from matplotlib.lines import Line2D\n",
    "# add a legend for the cell types\n",
    "legend_elements = [Line2D([0], [0], color=plt.get_cmap(\"tab10\")(i), label=ct) for i, ct in enumerate(pre_cts)]\n",
    "plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.2, 1), title=\"cell types\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
